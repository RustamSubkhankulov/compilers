# Лексический анализатор

Note: see READMEen.md for english version of this document.

### 1. Неформальное описание языка **Yazik++**
Лексическими единицами **Yazik++** являются целые числа, идентификаторы типов, идентификаторы объектов, строки, ключевые слова, а также
комментарии.
- **Целые числа** — это непустые последовательности цифр 0 – 9.
- **Идентификаторы** — это последовательности символов (кроме ключевых слов), состоящие из букв, цифр и символа подчеркивания.
Идентификаторы типов начинаются с заглавной буквы.
Идентификаторы объектов начинаются со строчной буквы.
- **Специальные синтаксические символы** – круглые скобки, оператор
присваивания, арифметические операторы.
- **Строки** – последовательности любых символов алфавита, заключенные в кавычки "...". Строки не могут содержать EOF и \0, но могут \n. Строка может быть перенесена на несколько строк при помощи '\'(C-like string literal).
- **Комментарий** начинается парой дефисов «--» и заканачивается новой
строкой (или EOF) и включает все символы между ними. Комментарии также можно писать, заключая текст в */*...*/*. Последняя форма комментариев может быть вложенной. Комментарии не могут
пересекать границы файла. 
- **Ключевые слова** – *else, false, if, loop, then, while, not, true,
print, println*. За исключением констант *true* и *false*, ключевые
слова нечувствительны к регистру. Чтобы соответствовать правилам
для других объектов, первая буква *true* и *false* должна быть строчной;
остальные буквы могут быть в верхнем или нижнем регистре.

### 2. flex/flex++

*flex*/*flex++* — инструмент для создания сканеров. Сканер — это программа, распознающая лексические закономерности в тексте. *flex* считывает заданные входные файлы или стандартный ввод, если имена файлов не указаны, для получения описания создаваемого сканера. Описание представлено в виде пар регулярных выражений и кода C/C++, называемых правилами. *flex* генерирует в качестве вывода исходный файл C, по умолчанию lex.yy.c, который определяет функцию yylex(). Этот файл можно скомпилировать и связать с библиотекой времени выполнения *flex* для создания исполняемого файла. При запуске исполняемого файла он анализирует входные данные на наличие регулярных выражений. Всякий раз, когда он его находит, он выполняет соответствующий код C/C++.

### 3. Структура
- *examples* - см. пункт **использование**
- *rules* - сожержит правила для построения лексического анализатора
- *inc* - заголовки, необходимые для работы лексера
- *tests* - заранее заготовленные в формате json данные для тестирования 
- *scripts* - директория с python скриптами для тестирования 

### 4. Сборка и использование

#### Сборка
Для сборки проекта необходима система сборки CMake версии 3.21 и выше, а также установленная утилита генерации лексический анализаторов *flex*.
Чтобы собрать проект, воспользуйтесь следующими командами:
- <code>cmake -B build -DDUMP_JSON=ON</code>
- <code>cmake --build build --target lexer</code>

Опция **DUMP_JSON** включает вывод результатов работы лексера в формате JSON.

#### Использование
Для проверки работы анализатора подготовлена директория *examples*, содержащая пример программы на языке **Yazik++**, предназначенная для демонстрации работы лексера.
Чтобы воспользоваться парсером, запустите исполняемый файл из директории *build* и подайте на вход текст программы или заранее заготовленную программу из *examples*.

### 5. Тестирование
Для тестирования работы лексера подготовлен *python-скрипт, использующий вывод анализатора и заранее заготовленные варианты токенов в формате JSON в **tests/test_data.json** для того, чтобы сверять результат работы с ожидаемыми классом и значением токенов.
Чтобы запустить тестирование, можно воспользоваться следующей командой (после сборки проекта):
<code>./scripts/etoe.py build/lexer tests/test_data.json</code>.
